# RAG Integration Testing - Findings Report

**Date:** 2025-10-30
**Status:** RAG retrieval working, LLM citation extraction failing

---

## Executive Summary

‚úÖ **RAG System is Working** - Successfully retrieving citations from CRA documents
‚ùå **LLM Not Extracting Citations** - Retrieved citations are not appearing in JSON response

---

## Test Commands Run

### 1. Direct RAG Test (Confirmed RAG Works)
```bash
# Created and ran direct RAG test
uv run python /tmp/test_rag_direct.py
```

**Results:**
- ‚úÖ RAG found 3 results for "meals" queries
- ‚úÖ Citations format: `T4002-P46-a73c204c` (NOT `LINE-####`)
- ‚ùå "lodging" expense_type returned 0 results (not indexed)

**Sample Output:**
```
üìã Test: Harrods Cookshop
   Query: Cookshop Harrods meals business expense tax deduction rules
   Expense types: ['meals']
   ‚úÖ Found 3 results
      1. Citation: T4002-P46-a73c204c
         Content: RULE: Part 4 ‚Äì Net income (loss) before adjustments...
         Source: https://www.canada.ca/en/revenue-agency.html
```

### 2. Agent Endpoint Tests

```bash
# Test 1: Harrods receipt
curl -s -X POST http://localhost:8000/api/web/upload-receipt-agents \
  -F "file=@/Users/manonjacquin/Documents/receipts/Harrods.jpg" \
  -F "additional_context=Business purchase" \
  -F "dry_run=true" | jq '.agent_details.full_agent_data.line_items[] | {desc: .original_description, category: .category, citations: .citations}'

# Test 2: Marriott PDF
curl -s -X POST http://localhost:8000/api/web/upload-receipt-agents \
  -F "file=@/Users/manonjacquin/Documents/receipts/marriot.pdf" \
  -F "additional_context=Hotel for business conference" \
  -F "dry_run=true" | jq '.agent_details.full_agent_data.line_items[] | {desc: .original_description, category: .category, citations: .citations}'
```

**Results:** Both returned `"citations": []` (empty)

**Sample Response:**
```json
{
  "desc": "Cookshop",
  "category": "Meals & Entertainment",
  "citations": [],
  "reasoning": "Per ITA Section 67.1, meals are 50% deductible. Although the CRA context does not explicitly mention meals..."
}
```

### 3. Server Log Analysis

```bash
# Check RAG activity in logs
grep "RAG search" /tmp/server.log | tail -20
```

**Key Findings:**
```
2025-10-30 17:04:20,081 - RAG search query: Cookshop Cookshop Harrods business expense tax deduction rules, expense_types: []
2025-10-30 17:04:20,176 - RAG search returned 3 results
2025-10-30 17:04:20,176 - RAG search raw results: [{'id': 'T4002-P46-a73c204c', ...}, ...]
```

```bash
# Check formatted RAG context
grep -A 20 "Formatted RAG context" /tmp/server.log | tail -25
```

**Output:**
```
Formatted RAG context being injected into prompt:
Relevant CRA Documents Found:

1. Citation ID: T4002-P46-a73c204c
   Source: https://www.canada.ca/en/revenue-agency.html
   Content: "RULE: Part 4 ‚Äì Net income (loss) before adjustments
Line 9200 ‚Äì Travel expenses
You can deduct travel expenses you incur to earn business and professional income. Travel expenses include public
transportation fares, hotel accommodation and meals..."
```

---

## Code Changes Made

### File: `src/quickexpense/services/agents/cra_rules_agent.py`

#### Change 1: Fixed Citation Format (Lines 387, 475)
```diff
- "citations": ["LINE-####", ...]
+ "citations": ["T4002-P##-########", ...]
```

**Reason:** RAG actually returns `T4002-P##-########` format, not `LINE-####`

#### Change 2: Improved RAG Category Mapping (Lines 720-735)
```python
# Mapping from application categories to simpler RAG-friendly terms
# Note: RAG database has limited expense_types indexed (mainly "meals")
# For other categories, we rely on keyword search in query without filter
RAG_CATEGORY_MAP = {
    "Travel-Lodging": "hotel travel accommodation",  # Changed from "lodging"
    "Travel-Meals": "meals",
    "Meals & Entertainment": "meals",
    "Fuel-Vehicle": "vehicle fuel",
    "Office-Supplies": "office supplies",
    "Capital-Equipment": "capital equipment",
    "Professional-Services": "professional services",
    "Travel-Taxes": "travel taxes",
}

# Only use expense_types filter for categories known to be indexed in RAG
INDEXED_EXPENSE_TYPES = {"meals"}
```

**Reason:**
- "lodging" returns 0 results in RAG (not indexed)
- Only "meals" is properly indexed as an expense_type
- Changed to use keyword search for other categories

#### Change 3: Enhanced Logging - INFO Level (Lines 762-779, 799)
```python
logger.info("RAG search query: %s, expense_types: %s", query, expense_types_filter)
logger.info("RAG search returned %d results", len(results) if results else 0)
logger.info("RAG search raw results: %s",
    [{"id": r.citation_id, "content": r.content[:100]} for r in results])
logger.info("Formatted RAG context being injected into prompt:\n%s", formatted_context)
```

**Reason:** Changed from DEBUG to INFO so logs are visible without LOG_LEVEL=DEBUG

#### Change 4: More Explicit Citation Instructions (Lines 358-370, 446-458)
```python
**AUTHORITATIVE CRA CONTEXT:**
‚ö†Ô∏è  IMPORTANT: Extract Citation IDs (T4002-P##-########) from below and include in "citations" field
---
{rag_context}
---

**CRITICAL INSTRUCTIONS:**
1. You MUST process EACH line item separately - do NOT aggregate or summarize
2. You MUST return valid JSON with a "processed_items" array
3. You MUST only use categories from the ALLOWED_CATEGORIES list below
4. **MANDATORY CITATION REQUIREMENTS:**
   - The CRA context above contains Citation IDs (format: T4002-P##-########)
   - You MUST extract Citation IDs from the CRA context section
   - You MUST include them in the "citations" array field
   - You MUST reference them in your reasoning
   - Example: "citations": ["T4002-P46-a73c204c"], reasoning: "Per T4002-P46-a73c204c..."
5. If an item's business purpose is ambiguous or possibly personal, use
   "Uncategorized-Review-Required"
6. Apply CRA rules: Meals 50%, Lodging 100%, GST/HST 100%, Office Supplies 100%
```

**Reason:** Added prominent warnings and concrete examples to guide LLM

#### Change 5: Improved Exception Handling (Lines 803-807)
```python
except ImportError:
    logger.error("`qe_tax_rag` package not found. RAG search is disabled.")
    return "RAG system not available. Rely on general tax knowledge."
except Exception as e:  # noqa: BLE001
    logger.warning("RAG search failed with %s: %s", type(e).__name__, e)
    return "RAG search failed. Rely on general tax knowledge."
```

**Reason:** Separate ImportError from general exceptions for better diagnostics

---

## Current Status

### What's Working ‚úÖ
1. RAG package installed and initialized (`qe-tax-rag==0.2.4`)
2. RAG search executes successfully (3 results per query)
3. Citations retrieved in correct format (`T4002-P##-########`)
4. RAG context formatted and injected into LLM prompts
5. Both agents (DataExtraction, CRArules) execute successfully
6. Logging shows RAG retrieval working perfectly

### What's NOT Working ‚ùå
1. LLM (TogetherAI Llama-3.1-70B) not populating `citations` field in JSON response
2. LLM says "CRA context does not explicitly mention meals" (FALSE - logs prove it does!)
3. LLM using general knowledge (ITA Section 67.1) instead of RAG citations
4. Empty citations array in all test responses: `"citations": []`

---

## Root Cause Analysis

The **LLM is receiving but ignoring the RAG context** despite:
- ‚úÖ RAG context successfully injected into prompt (confirmed in logs)
- ‚úÖ Multiple prominent warnings (‚ö†Ô∏è IMPORTANT)
- ‚úÖ Explicit instructions with concrete examples
- ‚úÖ Citation format matching response schema
- ‚úÖ Correct citation IDs present in context (T4002-P46-a73c204c, etc.)

**Evidence of LLM Ignoring Context:**
- Server logs: `Formatted RAG context being injected into prompt: ... Citation ID: T4002-P46-a73c204c`
- LLM response: `"Although the CRA context does not explicitly mention meals"` ‚Üê **FALSE STATEMENT**
- LLM response: `"citations": []` ‚Üê **EMPTY despite citations being provided**

**Possible Reasons:**
1. **Context window truncation** - RAG content not reaching LLM (unlikely - short receipts)
2. **Instruction following weakness** - Llama-3.1-70B not extracting structured data from prose
3. **Prompt structure** - RAG context too far from response schema (currently at top)
4. **Model prioritization** - LLM preferring its training data over provided context
5. **Output format constraint** - JSON schema parsing may be ignoring context

---

## Recommended Next Steps

### Option 1: Programmatic Citation Injection (Most Reliable) ‚≠ê RECOMMENDED
Extract citation IDs in Python and inject them as a simple list that requires no parsing:

```python
# In _get_rag_context(), modify to also return citation IDs
def _get_rag_context(...) -> tuple[str, list[str]]:
    # ... existing code ...
    citation_ids = [r.citation_id for r in results]
    return formatted_context, citation_ids

# In prompt, add simple list:
**CITATIONS YOU MUST COPY INTO YOUR RESPONSE:**
{json.dumps(citation_ids)}

CRITICAL: Copy these exact strings into your "citations" field.
Do not modify. Do not skip. Just copy.
```

**Pros:**
- No parsing required by LLM
- Simple copy operation
- Guaranteed to work

### Option 2: Post-Processing Fallback (Safety Net)
Add citations programmatically after LLM responds if field is empty:

```python
# In _parse_agent_response() or similar
def _ensure_citations(parsed_response, rag_citation_ids):
    for item in parsed_response.get("processed_items", []):
        if not item.get("citations") and rag_citation_ids:
            item["citations"] = rag_citation_ids
            logger.info("Added RAG citations to item (LLM failed to extract)")
    return parsed_response
```

**Pros:**
- Guarantees citations appear in output
- Works regardless of LLM behavior
- Non-intrusive (only activates when needed)

### Option 3: Test Different Model
Try with Gemini instead of TogetherAI to see if it's model-specific:

```python
# In agent config, switch to Gemini for CRA rules
config_list = [{
    "model": "gemini-2.0-flash-exp",
    "api_key": os.getenv("GEMINI_API_KEY"),
    "api_type": "google",
}]
```

**Pros:**
- Gemini may be better at following structured instructions
- Already using Gemini for image extraction (working well)

**Cons:**
- Increases Gemini API costs
- May reduce processing speed

### Option 4: Simplify RAG Context Format
Change from prose to bullet list with citations first:

```python
# Current format:
"""
1. Citation ID: T4002-P46-a73c204c
   Source: https://...
   Content: "RULE: Part 4..."
"""

# New format:
"""
**CITATION IDS (copy into your response):**
‚Ä¢ T4002-P46-a73c204c
‚Ä¢ T4002-P67-29e240f2
‚Ä¢ T4002-P67-be941333

**CONTENT:**
Line 9200 ‚Äì Travel expenses: You can deduct travel expenses...
"""
```

---

## Quick Reproduction

```bash
# 1. Start server (if not already running)
uv run fastapi dev src/quickexpense/main.py

# 2. Test Harrods receipt
curl -s -X POST http://localhost:8000/api/web/upload-receipt-agents \
  -F "file=@/Users/manonjacquin/Documents/receipts/Harrods.jpg" \
  -F "dry_run=true" > /tmp/test_result.json

# 3. Check citations field (will be empty)
cat /tmp/test_result.json | jq '.agent_details.full_agent_data.line_items[0].citations'
# Expected: []  ‚Üê EMPTY (this is the bug)

# 4. Verify RAG is working in server logs
grep "RAG search returned" /tmp/server.log | tail -1
# Expected: "RAG search returned 3 results"  ‚Üê RAG WORKS

# 5. See the actual citations retrieved
grep "RAG search raw results" /tmp/server.log | tail -1
# Expected: [{'id': 'T4002-P46-a73c204c', ...}]  ‚Üê CITATIONS EXIST

# 6. Contradiction: LLM says no context
cat /tmp/test_result.json | jq '.agent_details.full_agent_data.line_items[0].reasoning'
# Expected: "Although the CRA context does not explicitly mention meals..."  ‚Üê LLM LYING
```

---

## Files Modified

- `src/quickexpense/services/agents/cra_rules_agent.py`
  - Lines 358-370: Added prominent citation warnings
  - Lines 387, 475: Fixed citation format (LINE ‚Üí T4002)
  - Lines 446-458: Added mandatory citation requirements
  - Lines 720-735: Improved RAG category mapping + indexed types filter
  - Lines 762-779: Enhanced logging (DEBUG ‚Üí INFO)
  - Lines 799: Log formatted context
  - Lines 803-807: Improved exception handling

## Test Files Available

```bash
ls -lh /Users/manonjacquin/Documents/receipts/
```

Available test receipts:
- `Harrods.jpg` (703 KB) - Department store, 2 line items
- `marriot.pdf` (84 KB) - Hotel invoice, multiple line items (best for testing)
- `IMG_7597.HEIC` (2.3 MB) - iPhone HEIC photo
- `IMG_7598.HEIC` (2.5 MB) - iPhone HEIC photo
- `15-Sep-2025.jpeg` (2.9 MB) - Date-labeled receipt

---

## RAG-003 Task Status

**From RAG_INTEGRATION_PLAN.md:**

### RAG-001: Environment Setup ‚úÖ COMPLETE
- [x] Package installed
- [x] Database initializes
- [x] Version check passes
- [x] Search functionality works

### RAG-002: Service-Level Integration ‚úÖ COMPLETE
- [x] RAG initialized in FastAPI lifespan
- [x] `_get_rag_context()` helper method implemented
- [x] Helper searches and formats results
- [x] No crashes on startup

### RAG-003: Agent Prompt Augmentation ‚ö†Ô∏è **PARTIAL**
- [x] RAG context injected into prompts (confirmed in logs)
- [x] Prompts instruct LLM to use citations (multiple warnings added)
- [x] Response parser handles citations field
- [ ] **MISSING**: Citations appear in actual output ‚ùå ‚Üê **BLOCKING ISSUE**
- [ ] **MISSING**: Reasoning references citations ‚ùå
- [x] Debug logs confirm RAG retrieval ‚úÖ

**Blocker:** LLM not extracting/copying citations from RAG context into JSON response despite explicit instructions and examples.

---

## Success Criteria (From RAG_STATUS_ANALYSIS.md)

- [ ] **80%+ receipts get citations** - Currently: 0% ‚ùå
- [x] **Server logs show RAG initialization** - Yes ‚úÖ
- [x] **RAG searches execute** - Yes, 3 results per query ‚úÖ
- [ ] **Citations in correct format** - Format is correct (T4002-P##-########) but not appearing ‚ùå
- [ ] **Reasoning text references citations** - LLM says "context does not mention" (false) ‚ùå
- [x] **Processing time <20 seconds** - Yes, ~6 seconds ‚úÖ
- [x] **No exceptions in logs** - Clean execution ‚úÖ

**Overall Demo Readiness:** ‚ùå **NOT READY** - Critical feature (citations) not working

---

## Conclusion

**RAG infrastructure is 100% functional.** The problem is purely an LLM instruction-following issue. The TogetherAI Llama-3.1-70B model is:
1. Receiving the RAG context (proven by logs)
2. Ignoring it (proven by "context does not mention" statement)
3. Not extracting citations (proven by empty citations arrays)

**Recommended Fix:** Implement **Option 1 (Programmatic Citation Injection)** combined with **Option 2 (Post-Processing Fallback)** to guarantee citations appear in the response regardless of LLM behavior.

This is not a RAG problem - it's an LLM output formatting problem.

---

**Next Action:** Choose one of the 4 options above and implement. Option 1+2 combined is most reliable.
